<!DOCTYPE html>
<html lang="en">

<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
	
	<!-- title -->
	
	<title>
	
		Presto-基于内存的高效SQL交互查询引擎 | 
	 
	佳境的技术专区
	</title>
	
	<!-- keywords,description -->
	
		<meta name="keywords" content="SQL实时交互式查询," />
	 
		<meta name="description" content="Presto提供高效的交互式SQL查询服务" />
	

	<!-- favicon -->
	
	<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/Shmilyqjj/Shmilytech.github.io@hexo/themes/hexo-theme-tree/source/favicon.ico">
	
  

	
<link rel="stylesheet" href="/css/main.css">

	
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css">

	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/styles/darcula.min.css">


	
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/highlight.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

	
<script src="https://cdn.jsdelivr.net/npm/jquery-pjax@2.0.1/jquery.pjax.min.js"></script>

	
<script src="/js/main.js"></script>

	
		
<script src="https://cdn.jsdelivr.net/npm/leancloud-storage/dist/av-min.js"></script>

		
<script src="https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js"></script>

	
	
		<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	
<meta name="generator" content="Hexo 4.2.1"></head>

<body>
	<header id="header">
    <a id="title" href="/" class="logo">佳境的技术专区</a>
	<ul id="menu">
		<li class="menu-item">
			<a href="https://shmily-qjj.top/" class="menu-item-link" target="_self">
				<input type="image" src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/Resources/img/logo/gotoMain.png" width="90" height="35" alt="回到主站"/>
			</a>
		</li>
		<li class="menu-item">
			<a href="https://shmily-qjj.top/about/" target="_blank" rel="noopener" class="menu-item-link">
				<input type="image" src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/Resources/img/logo/aboutMe.png" width="90" height="35" alt="关于我"/>
			</a>
		</li>

		<li class="menu-item">
			<a href="https://github.com/Shmilyqjj" class="menu-item-link" target="_blank">
<!--				<i class="fa fa-github fa-2x"></i>-->
				<input type="image" src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/Resources/img/logo/myGithub.png" width="90" height="35" alt="关于我"/>
			</a>
		</li>
	</ul>
</header>

	
<div id="sidebar">
	<button id="sidebar-toggle" class="toggle" ><i class="fa fa-arrow-right " aria-hidden="true"></i></button>
	
	<div id="site-toc">
		<input id="search-input" class="search-input" type="text" placeholder="search...">
		<div id="tree">
			

			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										01数据结构与算法
									</a>
									
							<ul>
								<li class="file">
									<a href="/6a894937/">
										基础算法学习
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										02计算机网络
									</a>
									
							<ul>
								<li class="file">
									<a href="/39a9ed67/">
										Linux Bind服务配置DNS解析
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										03操作体统
									</a>
									
							<ul>
								<li class="file">
									<a href="/3f34ebe3/">
										基于Manjaro KDE版打造美观舒适开发环境
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										04编程语言
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										Java
									</a>
									
							<ul>
								<li class="file">
									<a href="/508b5c7/">
										系统学习JVM
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/6f97dc89/">
										线程进程与锁
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										Python
									</a>
									
							<ul>
								<li class="file">
									<a href="/2ed52290/">
										高效运行Python方案
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										05数据库
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										MySQL
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										原理深入
									</a>
									
							<ul>
								<li class="file">
									<a href="/7c15e85/">
										MySQL索引原理深入
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/1f7eb1b3/">
										数据库事务ACID理解
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										操作
									</a>
									
							<ul>
								<li class="file">
									<a href="/3c26421b/">
										Mysql Event Scheduler
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/96009187/">
										浅谈group by与distinct去重
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										06分布式
									</a>
									
							<ul>
								<li class="file">
									<a href="/4a17b156/">
										hello-world
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										07容器
									</a>
									
							<ul>
								<li class="file">
									<a href="/4a17b156/">
										hello-world
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										08大数据
									</a>
									
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										交互查询
									</a>
									
							<ul>
								<li class="file">
									<a href="/5f26355/">
										Apache Kudu总结
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/1ae37d82/">
										Impala-基于内存的高效SQL交互查询引擎
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file active">
									<a href="/4c197c46/">
										Presto-基于内存的高效SQL交互查询引擎
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										其他
									</a>
									
							<ul>
								<li class="file">
									<a href="/4b21953d/">
										分享我的技术调研流程
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/39595/">
										记一次参加QCon全球软件开发大会
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="file">
									<a href="/BigdataExceptionsSummary/">
										大数据平台常见异常处理汇总
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										平台运维
									</a>
									
							<ul>
								<li class="file">
									<a href="/38328/">
										CentOS7安装CDH6全程记录
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										数据仓库
									</a>
									
							<ul>
								<li class="file">
									<a href="/84534d72/">
										SeaTunnel开源数据同步平台
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/26078/">
										Sqoop学习笔记
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										数据可视化
									</a>
									
							<ul>
								<li class="file">
									<a href="/174820fd/">
										Apache Zeppelin初探
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										数据安全
									</a>
									
							<ul>
								<li class="file">
									<a href="/f5da73a2/">
										大数据脱敏方案调研
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/4cf161e5/">
										实现基于Spark的数据脱敏
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										数据湖
									</a>
									
							<ul>
								<li class="file">
									<a href="/44511/">
										Alluxio-基于内存的虚拟分布式存储系统
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/38dd005e/">
										Iceberg数据湖探索与实践
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="directory">
									<a href="#" class="directory">
										<i class="fa fa-plus-square-o"></i>
										离线计算
									</a>
									
							<ul>
								<li class="file">
									<a href="/7fbbfd34/">
										Hive3.x新特性
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/ee1c2df4/">
										Kyuubi原理与替代SparkThriftServer实践
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
							<ul>
								<li class="file">
									<a href="/pyspark_pandas/">
										使用PySpark优化Pandas
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
								</li>
								
							</ul>
			
								</li>
								
							</ul>
			
							<ul>
								<li class="file">
									<a href="/welcome/">
										欢迎
									</a>
								</li>
								<div class="article-toc" style="display: none;"></div>
							</ul>
			
		</div>
	</div>
</div>

	<!-- 引入正文 -->
	<div id="content">
		<h1 id="article-title">

	Presto-基于内存的高效SQL交互查询引擎
</h1>
<div class="article-meta">
	
	<span>佳境Shmily</span>
	<span>2021-03-12 14:46:00</span>
    
		<div id="article-categories">
            
                
                    <span>
                        <i class="fa fa-folder" aria-hidden="true"></i>
                        <a href="/categories/技术/">技术</a>
						
                    </span>
                
            
		</div>
    
</div>

<div id="article-content">
	<h1 id="Presto-高效SQL交互式查询引擎"><a href="#Presto-高效SQL交互式查询引擎" class="headerlink" title="Presto-高效SQL交互式查询引擎"></a>Presto-高效SQL交互式查询引擎</h1><h2 id="Presto简介"><a href="#Presto简介" class="headerlink" title="Presto简介"></a>Presto简介</h2><p>&emsp;&emsp;Presto是Facebook开源的分布式SQL查询引擎，适用于交互式分析查询的场景（OLAP），响应时间在小于 1 秒到几分钟的场景，数据量支持GB到PB字节。类似的工具有<a href="https://shmily-qjj.top/1ae37d82/" target="_blank" rel="noopener"><strong>Impala</strong></a>、<strong>ClickHouse</strong>等…</p>
<h2 id="Presto优缺点"><a href="#Presto优缺点" class="headerlink" title="Presto优缺点"></a>Presto优缺点</h2><p>优点：</p>
<ul>
<li>架构清晰，可不依赖任何外部系统独立运行。</li>
<li>Presto自身提供了对集群的监控。</li>
<li>基于纯内存计算，不需要写磁盘，效率高</li>
<li>自身更加轻量级资源调度，线程级别的Task，效率高</li>
<li>轮询查询结果并立刻返回结果，效率高</li>
<li>解耦数据源，统一查询入口，支持多个数据源不同表的联邦查询分析</li>
<li>MPP架构的优势-扩展性，节点独立，无锁资源竞争，无IO冲突，无共享数据</li>
<li>简单的数据结构，列式存储，逻辑行，大部分数据都可以轻易的转化成Presto所需要的这种数据结构。</li>
<li>丰富的接口，可完美对接外部存储系统，以及添加自定义的函数。</li>
</ul>
<p>缺点：</p>
<ul>
<li>无容错能力，无重试机制</li>
<li>不支持数据类型隐式转换</li>
<li>与Hive相比存在不小的语法差异、函数和UDF差异以及运算结果差异(如1/2在Hive结果为0.5在Presto结果为0)</li>
<li>Hive views are not supported.需要创建Presto视图</li>
<li>因为纯内存计算，不适合多个大表Join(聚合操作边读数据边计算，再清内存，再读数据再计算，这种耗的内存并不高；但关联操作可能产生大量临时数据，可能比Hive慢)</li>
<li>Coordinator单点问题（常见方案：ip漂移、Nginx代理动态获取等）</li>
<li></li>
</ul>
<h2 id="Presto原理"><a href="#Presto原理" class="headerlink" title="Presto原理"></a>Presto原理</h2><p><font size="3" color="red">在学习Presto原理前推荐先看看我之前关于Impala的文章：<a href="https://shmily-qjj.top/1ae37d82/" target="_blank" rel="noopener">《Impala-基于内存的高效SQL交互查询引擎》</a></font></p>
<h3 id="Presto架构和进程"><a href="#Presto架构和进程" class="headerlink" title="Presto架构和进程"></a>Presto架构和进程</h3><p><img src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/BlogImages/Presto/Presto-01.png" alt="alt"><br>&emsp;&emsp;Presto与Impala的架构极其相似，都是采用Master-Slave模型以及MPP架构,而且Presto的工作角色也与ImpalaDaemon的角色基本相同，Presto有三种工作角色：Coordinator,Worker和DiscoveryServer：</p>
<ul>
<li><font size="3" color="red">Coordinator</font>：即Master，负责管理Meta元数据，Worker节点，SQL的解析和调度，生成Stage和Task分发给Workers，负责合并结果集并返回给客户端。相当于结合了Impalad的Coordinator角色和Planner角色的功能，区别是每个Impalad节点都可以是Coordinator，而Presto只能有一个Coordinator，多个协调者进程会导致脑裂，查询任务会死锁。</li>
<li><font size="3" color="red">Worker</font>：负责计算和读写数据。相当于Impalad的Executor角色的功能。</li>
<li><font size="3" color="red">DiscoveryServer</font>：通常内嵌于Coordinator节点，也可以独立出来部署，功能类似ZK，类似Impala中的ImpalaStateStore，用于监控节点心跳，一般DS和Coordinator在同一节点。Worker启动会向DS进程注册，Coordinator可以从DS获取到所有正常提供服务的Worker。<br>Coordinator 与 Worker、Client 通信是通过 REST API。</li>
</ul>
<h3 id="Presto数据模型"><a href="#Presto数据模型" class="headerlink" title="Presto数据模型"></a>Presto数据模型</h3><p>Presto使用Catalog、Schema和Table这3层结构来管理数据：<br><img src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/BlogImages/Presto/Presto-06.png" alt="alt"></p>
<ul>
<li>Catalog：每个数据源都有一个名字，一个Catalog可包含多个Schema。通过show catalogs命令查看Presto已连接的所有数据源</li>
<li>Schema：相当于一个数据库实例，一个Schema(数据库)中有多个Table表，通过show schemas from hive命令查看hive数据源所有库</li>
<li>Table：相当于一张表，通过show tables from catalog_name.schema_name来查看库下有哪些表。定位一张表：数据源的类别.数据库.数据表</li>
</ul>
<p>Presto有两种存储单元：Page和Block</p>
<ul>
<li>Page：多行数据的集合，包含多个列的数据，这里的多行数据是逻辑行，实际是以列式存储。</li>
<li>Block：一列数据，根据不同类型的数据，通常采取不同的编码方式。（Kudu也有类似的思想）<ul>
<li>array类型的Block：应用于固定长度的类型如int、long、double，由两部分组成<ul>
<li>boolean valueIsNull[]表示每一行是否有值。</li>
<li>T values[] 每一行的具体值。</li>
</ul>
</li>
<li>可变长度的Block：String类型，由三部分组成：<ul>
<li>Slice：所有行数据拼接起来的字符串</li>
<li>int offsets[]：每行数据的起始偏移位置(每一行的长度等于下一行的起始偏移量减去当前行的起始偏移量)</li>
<li>boolean valueIsNull[]：是否空值，如果无值，偏移量与上一行相等</li>
</ul>
</li>
<li>固定长度的string类型的block：所有行的数据拼接成一长串Slice，每一行的长度固定</li>
<li>字典类型的Block：可以嵌套任意类型的Block，由两部分组成：<ul>
<li>字典</li>
<li>int ids[] 数据的编号，查找时先找到id，再从字典中拿到真实值</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Presto插件"><a href="#Presto插件" class="headerlink" title="Presto插件"></a>Presto插件</h3><p>了解了Presto的数据模型后，就可以利用插件来对接自己的系统。Presto提供了一套Connector接口，支持从自定义存储中读取元数据，以及列式存储数据。</p>
<ul>
<li>ConnectorMetadata:管理表的元数据，表的元数据，partition等信息。在处理请求时，需要获取元信息，以便确认读取的数据的位置。Presto会传入filter条件，以便减少读取的数据的范围。元信息可以从磁盘上读取，也可以缓存在内存中。</li>
<li>ConnectorSplit:一个IO Task处理的数据的集合，是调度的单元。一个split可以对应一个partition，或多个partition。</li>
<li>SplitManager:根据表的meta，构造split。</li>
<li>SlsPageSource:根据split的信息以及要读取的列信息，从磁盘上读取0个或多个page，供计算引擎计算。</li>
</ul>
<p>基于Presto的插件我们可以开发这些功能：</p>
<ul>
<li>对接自己的存储系统。</li>
<li>添加自定义数据类型。</li>
<li>添加自定义处理函数。</li>
<li>自定义权限控制。</li>
<li>自定义资源控制。</li>
<li>添加query事件处理逻辑。</li>
</ul>
<p>目前Presto已经支持很多类型的Connector，具体可见官方文档：<a href="https://prestodb.io/docs/current/connector.html" target="_blank" rel="noopener">Presto-Connectors</a></p>
<h3 id="Presto内存管理机制"><a href="#Presto内存管理机制" class="headerlink" title="Presto内存管理机制"></a>Presto内存管理机制</h3><p>&emsp;&emsp;Presto作为基于内存的计算引擎，对内存的分配很精细。Presto采用逻辑上的内存池，来管理不同类型的内存需求。Presto把机器的内存划分成三个内存池，分别是System Pool,Reserved Pool,General Pool。</p>
<ul>
<li>System Pool：保留给系统使用的内存，默认是Xmx的40%</li>
<li>General Pool：大部分Query使用这个内存池中的内存，因为大部分Query消耗内存并不高</li>
<li>Reserved Pool：用于给消耗内存最大的一个Query使用，这个内存池默认占10%的总内存，也表示一个Query在一台机器上最大的内存使用量</li>
</ul>
<p>&emsp;&emsp;<strong>为什么Presto会使用内存池机制？</strong><br>首先，System Pool为了系统正常运行以及数据传输时系统缓存消耗；在资源不充足时，一个消耗内存较大的Query开始运行，因为没足够空间所以会挂起等待执行，等一些消耗内存小的Query执行完，又有新的Query请求，内存一直不充足，如果没有Reserved Pool，这个消耗内存大的Query就会一直被挂起直到失败。为了防止这种情况，预留出Reserved Pool内存池供大Query执行。Presto每秒钟挑出来一个内存占用最大的query，允许它在所有机器上都能使用Reserved pool，避免一直没有可用内存供大Query使用。</p>
<p>&emsp;&emsp;<strong>如果大Query不在某些节点使用Reserved Pool就会浪费那台节点的预留内存，所以为什么不是单台机器中挑出占用内存最大的Task来使用Reserved Pool？</strong><br>这样设计会死锁，假设一个大Query的一个Task在某台机器可用Reserved Pool很快执行完，而另外一台机器的Task还是挂起状态，这个Query也会一直处于挂起状态，效率降低。</p>
<p>&emsp;&emsp;<strong>Presto内存管理分为两部分：Query内存管理和机器内存管理，是由Coordinator负责的</strong><br>Query内存管理：Query会划分为多个Task，每个Task会有一个线程循环获取Task状态包括内存使用情况，Query内存管理就是汇总这些Task的内存使用情况。<br>机器内存管理：Coordinator有一个线程定时轮询每台机器的内存状态</p>
<h3 id="Presto执行计划"><a href="#Presto执行计划" class="headerlink" title="Presto执行计划"></a>Presto执行计划</h3><p>Presto与Spark、Hive一样，都是使用Antlr进行语法解析，一条SQL经过如下步骤最终生成在每个节点执行的LocalExecutionPlan逻辑计划。<br><img src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/BlogImages/Presto/Presto-02.png" alt="alt"></p>
<p><img src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/BlogImages/Presto/Presto-07.png" alt="alt"><br>样例：</p>
<pre><code class="sql">select c1.rank, count(*) from dim.city c1 join dim.city c2 on c1.id = c2.id where c1.id &gt; 10 group by c1.rank limit 10;</code></pre>
<p>生成的逻辑计划：<br><img src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/BlogImages/Presto/Presto-04.jpg" alt="alt"></p>
<p>物理执行计划：逻辑计划的每一个SubPlan都会提交到一个或者多个Worker节点上执行，一个SubPlan也可以理解为一个Stage，SubPlan有几个重要的属性planDistribution、outputPartitioning、partitionBy属性。</p>
<ul>
<li>planDistribution有三种类型<ul>
<li>Source：数据源，会根据数据源大小确定分配多少个节点</li>
<li>Fixed：分配到固定个数的节点执行（Config配置中的query.initial-hash-partitions参数配置，默认是8）</li>
<li>None：这个SubPlan只分配到一个节点执行</li>
</ul>
</li>
<li>outputPartitioning有两种类型，表示这个SubPlan的输出是否按照<strong>partitionBy属性</strong>的key值对数据进行Shuffle。<ul>
<li>Hash：发生Shuffle</li>
<li>None：不进行Shuffle</li>
</ul>
</li>
</ul>
<p>在下面的执行计划中，SubPlan1和SubPlan0 PlanDistribution=Source，这两个SubPlan都是提供数据源的节点，SubPlan1所有节点的读取数据都会发向SubPlan0的每一个节点；SubPlan2分配8个节点执行最终的聚合操作；SubPlan3只负责输出最后计算完成的数据。只有SubPlan0的OutputPartitioning=HASH（存在AggregateNode计划），所以SubPlan2接收到的数据是按照rank字段Partition后的数据<br><img src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/BlogImages/Presto/Presto-05.png" alt="alt"></p>
<p>SQL提交并解析为SubPlan后的执行流程：<br>比如一条SQL最终生成4个SubPlan（0-3），其中0，1并行执行Join或聚合操作，其余串行执行，每个SubPlan都会分发到多个工作节点执行。<br><img src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/BlogImages/Presto/Presto-03.png" alt="alt"></p>
<ol>
<li>Coordinator通过HTTP协议调用Worker节点的/v1/task接口将执行计划分配给所有Worker节点（图中蓝色箭头）</li>
<li>SubPlan1的每个节点读取一个Split的数据并过滤后将数据分发给每个SubPlan0节点进行Join或聚合操作</li>
<li>SubPlan1的每个节点计算完成后按GroupBy Key的Hash值将数据分发到不同的SubPlan2节点</li>
<li>所有SubPlan2节点计算完成后将数据分发到SubPlan3节点</li>
<li>SubPlan3节点计算完成后通知Coordinator结束查询，并将数据发送给Coordinator</li>
</ol>
<p>总结一条SQL在Presto执行的完整流程：</p>
<ol>
<li>客户端通过HTTP协议发送一个查询语句给Presto集群的Coordinator</li>
<li>Coordinator接收到客户端传来的查询语句，对该语句进行解析、生成查询执行计划，并根据查询执行计划依次生成SqlQueryExecution -&gt; SqlStageExecution -&gt; HttpRemoteTask</li>
<li>Coordinator将每个Task分发到所需要处理的数据所在的Worker上进行分析</li>
<li>执行Source Stage的Task，这些Task通过Connector从数据源中读取所需要的数据</li>
<li>处于下游Stage中用的Task会读取上游Stage产生的输出结果，并在该Stage的每个Task所在的Worker内存中进行后续的计算和处理</li>
<li>Coordinator从分发的Task之后，一直持续不断的从最后的Stage中的Task获得计算结果，并将结果写入到缓存中，直到所有的计算结束</li>
<li>Client从提交查询后，就一直监听Coordinator中的本次查询结果集，立即输出。直到所有的结果都返回，本次查询结束</li>
</ol>
<h2 id="部署与使用"><a href="#部署与使用" class="headerlink" title="部署与使用"></a>部署与使用</h2><h3 id="Presto集群部署"><a href="#Presto集群部署" class="headerlink" title="Presto集群部署"></a>Presto集群部署</h3><p>下载Presto<br>使用<a href="https://www.toolbaba.cn/d/dev_guid" target="_blank" rel="noopener">GUID生成工具</a>生成所需机器数量相等的GUID，用于配置node.properties</p>
<pre><code class="shell">cd $PRESTO_HOME
mkdir etc
# node.properties配置节点信息(每个节点不同)
vim etc/node.properties
node.environment=cdh    一个Presto集群有相同的env名称，我这里起名叫cdh
node.id=AB1C6EAC-8CF6-B397-EFD3-77C8AB041CD5  刚刚生成的GUID，每个节点都要不同的GUID
node.data-dir=/var/presto/data   存放数据的目录
# JVM配置(每个节点相同)
vim etc/jvm.config
-server
-Xmx4G
-XX:+UseG1GC
-XX:G1HeapRegionSize=32M
-XX:+UseGCOverheadLimit
-XX:+ExplicitGCInvokesConcurrent
-XX:+HeapDumpOnOutOfMemoryError
-XX:+ExitOnOutOfMemoryError
# Presto配置 Coordinator节点 非生产集群单个节点可以既为Coordinator又为Worker可设node-scheduler.include-coordinator=true
vim etc/config.properties(每个节点不同)
coordinator=true  是否为Coordinator
node-scheduler.include-coordinator=false  是否在Coordinator节点执行计算（会影响性能，不建议true）
http-server.http.port=8080  请求发送的HTTP端口
query.max-memory=4GB  单条Query占用集群内存的最大值
query.max-memory-per-node=1GB  单条Query单个节点占用内存的最大值
query.max-total-memory-per-node=2GB  单条Quey单个节点占用的执行内存和系统内存(readers, writers, and network buffers, etc.)总和的最大值
discovery-server.enabled=true  整合Coordinator和DiscoveryServer为一个进程，使用同一个端口
discovery.uri=http://cdh101:8080
# Presto配置 Worker节点
vim etc/config.properties
coordinator=false
http-server.http.port=8080
query.max-memory=4GB
query.max-memory-per-node=1GB
query.max-total-memory-per-node=2GB
discovery.uri=http://cdh101:8080  指定集群中已有的DS服务HTTP地址
# 日志等级设置(每个节点相同)
vim etc/log.properties
com.facebook.presto=INFO
# 配置支持Hive数据源 (每个节点相同)(其他数据源可参考https://prestodb.io/docs/current/connector)
mkdir etc/catalog
vim etc/catalog/hive.properties
connector.name=hive-hadoop2
hive.metastore.uri=thrift://cdh101:9083
hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml 
# ###############################################
ln -s /var/presto/data/var/log log  将日志链接到安装目录
在各个节点后台启动Presto：bin/launcher start
也可以在前台运行,查看具体的日志：bin/launcher run
停止服务进程命令：bin/laucher stop
启动脚本编写
#!/bin/bash
# 需要root用户免密
# 使用 sh presto-server.sh start

PRESTO_HOME=/opt/modules/presto-server-0.248

OP=$1
if [ &quot;$OP&quot; == &quot;start&quot; ] || [ &quot;$OP&quot; == &quot;stop&quot; ] || [ &quot;$OP&quot; == &quot;status&quot; ] || [ &quot;$OP&quot; == &quot;restart&quot; ]; then
  echo &quot;Begin to $OP Presto Coordinator and Workers.&quot;
  for((host=101; host&lt;=104; host++)); do
          echo --- &quot;$OP&quot; presto server on cdh$host ---
          ssh -l root cdh$host $PRESTO_HOME/bin/launcher &quot;$OP&quot;
  done
else
  echo &quot;Usage: ./presto-server.sh [start|stop|restart|status]&quot;
  exit 1
fi
# ###############################################
根据自己的版本下载presto客户端：https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/0.248/presto-cli-0.248-executable.jar
chmod a+x presto-cli-0.248-executable.jar
mv presto-cli-0.248-executable.jar presto
ln -s /opt/modules/presto-server-0.248/presto /usr/bin/presto
进入Presto客户端(指定数据源hive，指定库名default) presto --server cdh101:8080 --catalog hive --schema default
# ###############################################
# 配置MySQL数据源
vim etc/catalog/mysql.properties
connector.name=mysql
connection-url=jdbc:mysql://cdh102:3306
connection-user=root
connection-password=123456</code></pre>
<h3 id="Presto-On-Yarn部署"><a href="#Presto-On-Yarn部署" class="headerlink" title="Presto On Yarn部署"></a>Presto On Yarn部署</h3><pre><code class="text">待补充</code></pre>
<h3 id="Presto-On-kerberized-Hive"><a href="#Presto-On-kerberized-Hive" class="headerlink" title="Presto On kerberized Hive"></a>Presto On kerberized Hive</h3><p>Hive集群是Kerberos认证的安全集群,Presto Hive插件需要设置kerberos以及sasl相关属性,否则会报如下错误</p>
<pre><code class="text">-执行 ./presto --debug --execute &#39;show schemas&#39; --server presto-server:8080 --catalog hive
Caused by: org.apache.thrift.transport.TTransportException: hms:9083: null
        at com.facebook.presto.hive.metastore.thrift.Transport.rewriteException(Transport.java:92)
        at com.facebook.presto.hive.metastore.thrift.Transport.access$000(Transport.java:32)
        at com.facebook.presto.hive.metastore.thrift.Transport$TTransportWrapper.readAll(Transport.java:169)
        at org.apache.thrift.protocol.TBinaryProtocol.readStringBody(TBinaryProtocol.java:380)
        at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:230)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_all_databases(ThriftHiveMetastore.java:1187)
        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_all_databases(ThriftHiveMetastore.java:1175)
        at com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastoreClient.getAllDatabases(ThriftHiveMetastoreClient.java:89)
        at com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore.getMetastoreClientThenCall(ThriftHiveMetastore.java:1068)
        at com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore.lambda$getAllDatabases$0(ThriftHiveMetastore.java:219)
        at com.facebook.presto.hive.metastore.thrift.HiveMetastoreApiStats.lambda$wrap$0(HiveMetastoreApiStats.java:48)
        at com.facebook.presto.hive.RetryDriver.run(RetryDriver.java:139)
        at com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore.getAllDatabases(ThriftHiveMetastore.java:218)
        ... 57 more
        Suppressed: org.apache.thrift.transport.TTransportException: hms:9083: null
                ... 71 more
        Caused by: org.apache.thrift.transport.TTransportException
                at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
                at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
                at com.facebook.presto.hive.metastore.thrift.Transport$TTransportWrapper.readAll(Transport.java:166)
                ... 68 more</code></pre>
<p>参考:<a href="https://prestodb.io/docs/current/connector/hive-security.html" target="_blank" rel="noopener">Presto hive-security</a><br>Presto默认没有使用权限认证,所有Query都是以运行PrestoServer进程的用户身份提交的.Presto Hive Plugin支持连接Kerberos集群以扩展权限管理,对数据做访问权限控制.集成Kerberos后,Presto可以模拟执行Query的用户来访问数据,数据权限得到控制.<br>vim etc/catalog/hive.properties 添加kerberos相关参数,并重启PrestoServers</p>
<pre><code class="properties">connector.name=hive-hadoop2
hive.metastore.uri=thrift://metastoreIP:9083
hive.config.resources=/etc/ecm/hadoop-conf/core-site.xml,/etc/ecm/hadoop-conf/hdfs-site.xml
hive.metastore.authentication.type=KERBEROS
hive.metastore.service.principal=hive/metastoreIP@REALM.COM
hive.metastore.client.principal=hive/prestoServerIp@REALM.COM
hive.metastore.client.keytab=/opt/keytabs/hive.keytab
hive.hdfs.authentication.type=KERBEROS
hive.hdfs.impersonation.enabled=true
hive.hdfs.presto.principal=hive/prestoServerIp@REALM.COM
hive.hdfs.presto.keytab=/opt/keytabs/hive.keytab</code></pre>
<p>错误与异常排查解决:<br>在使用OSS存储的Hive集群使用Presto报错</p>
<pre><code class="err">Query 20220808_061604_00004_dp628 failed: java.lang.ClassNotFoundException: Class com.aliyun.jindodata.oss.JindoOssFileSystem not found
Query 20220809_023611_00025_43gsw failed: java.lang.NoClassDefFoundError: com/aliyun/jindodata/api/spec/JdoException</code></pre>
<p>解决:<br>拷贝jindo-sdk-4.4.1.jar和jindo-core-4.4.1.jar到$PRESTO_HOME/plugin/hive-hadoop2/</p>
<p>presto:db_name&gt; select * from table_name limit 1;<br>Query 20220808_061604_00004_dp628, FAILED, 1 node<br>Splits: 17 total, 0 done (0.00%)<br>0:01 [0 rows, 0B] [0 rows/s, 0B/s]<br>查看Presto WebUI发现如下报错:</p>
<pre><code class="err">com.facebook.presto.spi.PrestoException: For input string: &quot;30s&quot;
    at com.facebook.presto.hive.BackgroundHiveSplitLoader$HiveSplitLoaderTask.process(BackgroundHiveSplitLoader.java:128)
    at com.facebook.presto.hive.util.ResumableTasks.safeProcessTask(ResumableTasks.java:47)
    at com.facebook.presto.hive.util.ResumableTasks.access$000(ResumableTasks.java:20)
    at com.facebook.presto.hive.util.ResumableTasks$1.run(ResumableTasks.java:35)
    at com.facebook.airlift.concurrent.BoundedExecutor.drainQueue(BoundedExecutor.java:78)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: &quot;30s&quot;
    at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
    at java.lang.Long.parseLong(Long.java:589)
    at java.lang.Long.parseLong(Long.java:631)
    at org.apache.hadoop.conf.Configuration.getLong(Configuration.java:1311)
    at org.apache.hadoop.hdfs.DFSClient$Conf.&lt;init&gt;(DFSClient.java:502)</code></pre>
<p>检查hive.config.resources中的hdfs-site.xml等文件,发现dfs.client.datanode-restart.timeout等配置参数值为30s,修改为30并重启PrestoServer即可.</p>
<h3 id="Presto-On-Iceberg"><a href="#Presto-On-Iceberg" class="headerlink" title="Presto On Iceberg"></a>Presto On Iceberg</h3><p>Presto兼容Iceberg,参考<a href="https://prestodb.io/docs/current/connector/iceberg.html" target="_blank" rel="noopener">Iceberg Connector</a>配置Iceberg连接器配置vim etc/catalog/iceberg.properties 支持的Iceberg Catalog Type有hive和hadoop两种,配置方式分别为如下<br>iceberg.catalog.type=hive的配置方式:</p>
<pre><code class="properties">connector.name=iceberg
hive.metastore.uri=thrift://metastoreIP:9083
hive.metastore.authentication.type=KERBEROS
hive.metastore.service.principal=hive/metastoreIP@REALM.COM
hive.metastore.client.principal=hive/prestoServerIp@REALM.COM
hive.metastore.client.keytab=/opt/keytabs/hive.keytab
iceberg.catalog.type=hive
iceberg.file-format=PARQUET
iceberg.compression-codec=SNAPPY
hive.config.resources=/etc/ecm/hadoop-conf/core-site.xml,/etc/ecm/hadoop-conf/hdfs-site.xml</code></pre>
<p>iceberg.catalog.type=hadoop的配置方式:</p>
<pre><code class="properties">connector.name=iceberg
hive.metastore.uri=thrift://metastoreIP:9083
iceberg.catalog.type=hadoop
iceberg.file-format=PARQUET
iceberg.catalog.cached-catalog-num=10
iceberg.hadoop.config.resources=/etc/ecm/hadoop-conf/core-site.xml,/etc/ecm/hadoop-conf/hdfs-site.xml
iceberg.catalog.warehouse=hdfs://nameservice/user/iceberg/warehouse</code></pre>
<p>然后重启PrestoServer</p>
<p>与Hive整合：<br>到<a href="https://iceberg.apache.org/releases/" target="_blank" rel="noopener">Iceberg-Releases</a>页面下载对应版本（可在$PRESTO_HOME/plugins/iceberg下查看Presto Iceberg版本）的Hive runtime Jar。<br>下载<a href="https://repo1.maven.org/maven2/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar" target="_blank" rel="noopener">libfb303-0.9.3.jar</a>依赖包。<br>在hive-site.xml中添加</p>
<pre><code class="xml">&lt;property&gt;
    &lt;name&gt;iceberg.engine.hive.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;</code></pre>
<p>所有hive节点创建/etc/hive/auxlib目录，将两个jar放入<br>配置HiveServer2生效jar，在hive-site.xml添加</p>
<pre><code class="xml">&lt;property&gt;
    &lt;name&gt;hive.aux.jars.path&lt;/name&gt;
    &lt;value&gt;/etc/hive/auxlib&lt;/value&gt;
&lt;/property&gt;</code></pre>
<p>配置hiveCli生效jar<br>hive-env.sh增加export HIVE_AUX_JARS_PATH=/etc/hive/auxlib<br>重启HiveServer2<br>在hive创建Iceberg表</p>
<pre><code class="hql">CREATE TABLE iceberg_db.hive_iceberg_table (
    id BIGINT,
    name STRING
)
STORED BY &#39;org.apache.iceberg.mr.hive.HiveIcebergStorageHandler&#39;;</code></pre>
<p>使用Hive和Presto读写和操作Iceberg表</p>
<pre><code class="sql">hive&gt; insert into hive_iceberg_table values (1,&#39;qjj&#39;),(2,&#39;abc&#39;);
presto&gt; select * from hive_iceberg_table;
presto&gt; insert into hive_iceberg_table values (3,&#39;jjq&#39;),(4,&#39;def&#39;);
hive&gt; select count(1) from hive_iceberg_table;</code></pre>
<p>相关TroubleShooting</p>
<ol>
<li>Vectorization only supported for Hive 3+<br>解决：设置set hive.vectorized.execution.enabled=false;</li>
<li>Presto插入Iceberg表String类型数据后，Hive读取不到String的值而是显示java.nio.HeapByteBuffer<br>待排查…</li>
</ol>
<h3 id="Presto语法："><a href="#Presto语法：" class="headerlink" title="Presto语法："></a>Presto语法：</h3><pre><code class="sql">SHOW CATALOGS; 查看Presto集群当前可用数据源
SHOW SCHEMAS;  查看当前数据源有哪些库
SHOW SCHEMAS FROM hive;  查看hive数据源的所有库 （FROM可以用IN替换)
SHOW TABLES; 查看当前Schema库下有哪些表
SHOW TABLES FROM hive.default;  查看hive数据源下default库下的所有表
CREATE SCHEMA hive.web WITH (location = &#39;hdfs:///user/hive/warehouse/web/&#39;)  # 建库
ALTER SCHEMA old_db_name RENAME TO new_db_name  # 改库名
-- 建表
CREATE TABLE hive.test.page_views (
  view_time timestamp,
  user_id bigint,
  page_url varchar,
  ds date,
  country varchar
)
WITH (
  format = &#39;Parquet&#39;,
  partitioned_by = ARRAY[&#39;ds&#39;, &#39;country&#39;],
  bucketed_by = ARRAY[&#39;user_id&#39;],
  bucket_count = 50
);
-- 查看表
desc hive.test.page_views;
-- 查看表字段
SHOW COLUMNS IN hive.test.page_views;
-- 统计表信息（类似于Spark的Analyzed table）（数据大小，行数，最大值，最小值，无重复值个数，NULL值占比）
SHOW STATS FOR table
SHOW STATS FOR ( SELECT * FROM table [ WHERE condition ] )
-- 查看逻辑计划（相比Spark的逻辑计划，多了每个节点的行数及数据大小,CPU操作数,内存消耗,网络传输大小）
EXPLAIN sql
EXPLAIN ANALYZE sql  -- 更全面 但会触发计算
-- 枚举表
SELECT * FROM (
    VALUES
        (1, &#39;a&#39;),
        (2, &#39;b&#39;),
        (3, &#39;c&#39;)
) t (id, name);
SELECT * FROM (
    VALUES
        (1, &#39;a&#39;, ARRAY[1, 2, 3]),
        (2, &#39;b&#39;, ARRAY[4, 5, 6]),
        (3, &#39;c&#39;, ARRAY[7, 8, 9])
) AS t (id, name, arr);
-- 准备好执行语句,延迟执行
PREPARE statement_1 FROM
show tables;
PREPARE statement_2 FROM
select * from test;
EXECUTE statement_2;
EXECUTE statement_1;
DEALLOCATE PREPARE statement_1;
DEALLOCATE PREPARE statement_2;
-- timestamp字段过滤条件 kafka_timestamp字段类型为timestamp(6)
select appid from iceberg.iceberg_db.iceberg_table where ds=&#39;2022120910&#39; and kafka_timestamp = from_unixtime(1670625207.945);  -- 效率更高
select appid from iceberg.iceberg_db.iceberg_table where ds=&#39;2022120910&#39; and to_unixtime(kafka_timestamp) = 1670525207.945;</code></pre>
<p>Presto支持事务，相关命令有<a href="https://prestodb.io/docs/current/sql/commit.html" target="_blank" rel="noopener">COMMIT</a>,<a href="https://prestodb.io/docs/current/sql/start-transaction.html" target="_blank" rel="noopener">START TRANSACTION</a>,<a href="https://prestodb.io/docs/current/sql/rollback.html" target="_blank" rel="noopener">ROLLBACK</a><br>更多语法：<a href="https://prestodb.io/docs/current/sql.html#" target="_blank" rel="noopener">SQL Statement Syntax</a></p>
<h3 id="Presto-WEBUI"><a href="#Presto-WEBUI" class="headerlink" title="Presto WEBUI"></a>Presto WEBUI</h3><p>访问WEBUI地址即为DiscoveryServer地址：<a href="http://cdh101:8080/ui/" target="_blank" rel="noopener">http://cdh101:8080/ui/</a><br>透过WEB UI可以查看到每个SQL Query的执行相关状态信息以及Presto集群的运行状态信息。<br><img src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/BlogImages/Presto/Presto-08.jpg" alt="alt"></p>
<table>
<thead>
<tr>
<th align="center">任务状态</th>
<th align="center">原因</th>
</tr>
</thead>
<tbody><tr>
<td align="center">QUEUED</td>
<td align="center">等待执行</td>
</tr>
<tr>
<td align="center">PLANNING</td>
<td align="center">正在转成执行计划</td>
</tr>
<tr>
<td align="center">RUNNING</td>
<td align="center">正在运行Query</td>
</tr>
<tr>
<td align="center">BLOCKED</td>
<td align="center">阻塞中，等待内存、Buffer等资源</td>
</tr>
<tr>
<td align="center">FINISHING</td>
<td align="center">即将完成执行，正在返回数据</td>
</tr>
<tr>
<td align="center">FINISHED</td>
<td align="center">执行完成</td>
</tr>
<tr>
<td align="center">FAILED</td>
<td align="center">执行失败</td>
</tr>
</tbody></table>
<p>BLOCKED状态是正常的，但持续很长时间都是这个状态就需要排查下原因，有很多可能的原因：<br>1.内存不足<br>2.磁盘或网络I/O瓶颈<br>3.数据倾斜(所有数据都转移到几个worker上)<br>4.并行度低(只有几个worker可用)<br>5.某个Stage查询开销较高（如select *操作数据过多）<br>对于某个Query的执行过程相关监控信息，可以在WebUI上点那个Query ID即可查看<br><img src="https://blog-images-1257889704.cos.ap-chengdu.myqcloud.com/BlogImages/Presto/Presto-09.png" alt="alt"></p>
<h3 id="连接Presto"><a href="#连接Presto" class="headerlink" title="连接Presto"></a>连接Presto</h3><p>用户连接Presto的主要方式：Presto-Cli,JDBC,PyHive,PrestoOnSpark等。<br>Presto-Cli:</p>
<pre><code class="shell">wget https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/0.248/presto-cli-0.248-executable.jar
mv presto-cli-0.248-executable.jar presto
chmod a+x presto
presto --server cdh101:8080 --catalog hive --schema default --user admin</code></pre>
<p>JDBC:</p>
<pre><code class="java">&lt;dependency&gt;
    &lt;groupId&gt;com.facebook.presto&lt;/groupId&gt;
    &lt;artifactId&gt;presto-jdbc&lt;/artifactId&gt;
    &lt;version&gt;0.248&lt;/version&gt;
&lt;/dependency&gt;

public class PrestoConnetToJDBC {
    public static void main(String[] args) throws SQLException {
        // 1.简单创建连接
//        String url = &quot;jdbc:presto://cdh101:8080/hive/staging_db_users&quot;;
//        Connection connection = DriverManager.getConnection(url, &quot;root&quot;, null);
//        connection.prepareStatement(&quot;show tables&quot;);

        // 2.带参数创建连接
        String url = &quot;jdbc:presto://cdh101:8080/hive/staging_db_users&quot;;
        Properties properties = new Properties();
        properties.setProperty(&quot;user&quot;, &quot;root&quot;);
        properties.setProperty(&quot;password&quot;, &quot;&quot;);
        properties.setProperty(&quot;SSL&quot;, &quot;false&quot;);
        Connection connection = DriverManager.getConnection(url, properties);

        // 3.带参数创建连接
      //  String url = &quot;jdbc:presto://cdh101:8080/hive/staging_db_users?user=root&amp;password=secret&amp;SSL=true&quot;;
      //  Connection connection = DriverManager.getConnection(url);
        // 读数据或做其他操作
            Statement stmt = connection.createStatement();
            ResultSet rs = stmt.executeQuery(&quot;select * from tb_user_info limit 10&quot;);
            while (rs.next()){
                System.out.println(rs.getString(1) + &quot;--&quot; + rs.getString(2));
            }
    }
}</code></pre>
<p>python:<br>pip3 install sasl<br>pip3 install thrift<br>pip3 install thrift-sasl<br>pip3 install PyHive<br>pip3 install sqlalchemy<br>pip3 install requests</p>
<pre><code class="python">from sqlalchemy import *
from sqlalchemy.engine import create_engine
from sqlalchemy.schema import *
import pandas as pd
# Presto
engine = create_engine(&#39;presto://admin:123456@cdh101:8080/mysql/db_users&#39;)  # 密码连接
engine = create_engine(&#39;presto://cdh101:8080/mysql/db_users&#39;) 
df = pd.read_sql(&quot;select * from tb_user_records limit 10&quot;,engine) 
print(df)</code></pre>
<p>PrestoOnSpark:<br>Presto on Spark即利用Spark作为Presto查询的执行框架<br>操作：<a href="https://prestodb.io/docs/current/installation/spark.html" target="_blank" rel="noopener">Executing Presto on Spark</a></p>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><p>Presto参数调优：<a href="https://prestodb.io/docs/current/admin/properties.html" target="_blank" rel="noopener">Properties Reference</a>，官方详细介绍了Presto的config.properties中的常规参数如join参数，内存管理参数，Spilling溢出磁盘相关参数，数据网络交换参数（一个查询任务不同Stage会有不同节点交换数据，这些参数提高网络利用率），任务参数，节点调度参数，优化器参数以及正则相关参数</p>
<ol>
<li><p>Presto不是纯内存计算吗？为什么要溢写到磁盘？<br>正常情况Presto执行Query请求的内存资源超过query_max_memory或query_max_memory_per_node这个Query就会被终止。<br>溢写磁盘机制：Presto节点空闲时Query会利用全部内存资源，如果没足够内存，Query被迫使用磁盘来存储中间数据，写入磁盘再从磁盘读取回来，有较高的IO开销。<br>解决IO开销高的方法：spiller-spill-path可设置多个磁盘多个路径，并行读写提高IO效率；spill-encryption-enabled启用压缩用CPU开销换IO开销<br>局限：系统无法将中间数据划分成足够小的块，导致从磁盘加载块数据时发生OOM；只有Join和聚合操作可以落盘</p>
</li>
<li><p>资源隔离机制？<br>Presto可以像Yarn一样将全部资源分为多个资源组（通过配置文件etc/resource-groups.properties），资源组也可以有子组。配置可参考：<a href="https://prestodb.io/docs/current/admin/resource-groups.html" target="_blank" rel="noopener">Resource Groups</a></p>
</li>
<li><p>Session配置管理<br>通过配置etc/session-property-config.properties可以将任务分为不同类型（如即时查询，etl，高消耗etl等…），然后对不同类型的任务配置不同的资源，参数（configuration property）。具体见：<a href="https://prestodb.io/docs/current/admin/session-property-managers.html" target="_blank" rel="noopener">Session Property Managers</a><br>（Presto参数分为configuration property和session property）</p>
</li>
<li><p>分布式排序<br>需要排序数据超过单节点query.max-memory-per-node大小限制，默认会启用分布式排序（参数distributed-sort）。排序速度不会随节点数量增加而线性加快，因为排序后数据在单个节点合并</p>
</li>
<li><p>使用Alluxio基于内存缓存热点数据和降低远程机房网络IO影响<br>注意:计算与存储节点共置的场景下，Alluxio对Presto的加速效果并不明显<br>Alluxio分布式缓存数据湖相关知识可以参考我的另一篇文章：<a href="https://shmily-qjj.top/44511/" target="_blank" rel="noopener">Alluxio-基于内存的虚拟分布式存储系统</a><br>Presto结合Alluxio配置和使用可以参考官方文档：<a href="https://prestodb.io/docs/current/cache.html" target="_blank" rel="noopener">Alluxio Cache Service</a></p>
</li>
<li><p>基于成本的优化<br>Join操作对查询性能影响大，Presto也会像Spark一样，评估Join的表的顺序，自动选择最低成本的Join表顺序。<br>对应的ConfigurationProperty(optimizer.join-reordering-strategy)<br>对应的SessionProperty(join_reordering_strategy)<br>参数值：AUTOMATIC全自动的Join优化，ELIMINATE_CROSS_JOINS默认参数消除不必要的笛卡尔积，NONE按SQL语法的顺序Join</p>
</li>
<li><p>分布式Join算法选择<br>Presto的Join是基于Hash的，分为两种方式：Partitioned和Broadcast<br>Partitioned：每个节点都持有一部分Hash后的数据，然后Join<br>Broadcast：一个表被广播到所有参与Join计算节点<br>对应的ConfigurationProperty(join-distribution-type)<br>对应的SessionProperty(join_distribution_type)<br>参数值：AUTOMATIC全自动的Join算法选择，BROADCAST，PARTITIONED(默认)</p>
</li>
<li><p>Presto会根据元数据信息读取分区数据，合理设置分区能减少Presto数据读取量，提升查询性能</p>
</li>
<li><p>Presto对ORC格式文件的读取进行了特定优化，相对于Parquet，Presto对ORC支持更好(Impala对Parquet支持更好)</p>
</li>
<li><p>数据压缩可以减少节点间数据传输对网络带宽的压力，对于即席查询需要快速解压，建议采用Snappy压缩算法</p>
</li>
<li><p>预先排序以提高性能<br>对于已经排序的数据，在查询的数据过滤阶段，ORC格式支持跳过读取不必要的数据。比如对于经常需要过滤的字段可以预先排序。<br>INSERT INTO table nation_orc partition(p) SELECT * FROM nation SORT BY n_name;<br>如果需要过滤 n_name 字段，则性能将提升：<br>SELECT count(*) FROM nation_orc WHERE n_name=’AUSTRALIA’;</p>
</li>
<li><p>一些Presto优化常识</p>
<ul>
<li>因为列式存储，尽量避免select *，而是<strong>只查询有用字段</strong></li>
<li>对于有分区的表，<strong>where语句中优先使用分区字段进行过滤</strong></li>
<li>合理安排<strong>group by字段的顺序</strong>有助于提高查询效率，这些字段按照每个字段distinct数据多少进行降序排列</li>
<li><strong>多表Join时，数据越多的表越往后放，Left join时，条件过滤尽量在ON阶段完成，而少用WHERE，Join左边尽量放小数据量的表，而且最好是重复关联键少的表</strong></li>
<li>将使用频繁的表作为一个子查询抽离出来，避免多次读取IO</li>
</ul>
</li>
<li><p>Order by时使用limit：Order by需要扫描数据到单个worker节点进行排序，导致单个worker需要大量内存。如果是查询Top N或者Bottom N，使用limit可减少排序计算和内存压力</p>
</li>
<li><p>精度要求低的场景使用近似聚合函数：Presto有一些近似聚合函数，对于允许有少量误差的查询场景，使用这些函数对查询性能有大幅提升。比如使用approx_distinct()函数比Count(distinct x)有大概2~3%的误差。</p>
</li>
<li><p>用regexp_like代替多个like语句：Presto查询优化器没有对多个like语句进行优化，使用regexp_like对性能有较大提升</p>
<pre><code class="sql">[GOOD]
SELECT
xxx
FROM
access
WHERE
regexp_like(method, &#39;GET|POST|PUT|DELETE&#39;)
[BAD]
SELECT
xxx
FROM
access
WHERE
method LIKE &#39;%GET%&#39; OR
method LIKE &#39;%POST%&#39; OR
method LIKE &#39;%PUT%&#39; OR
method LIKE &#39;%DELETE%&#39;</code></pre>
</li>
<li><p>使用Rank函数代替row_number函数来获取Top N:在进行一些分组排序场景时，使用rank函数性能更好</p>
<pre><code class="sql">[GOOD]
SELECT checksum(rnk)
FROM (
SELECT rank() OVER (PARTITION BY l_orderkey, l_partkey ORDER BY l_shipdate DESC) AS rnk
FROM lineitem
) t
WHERE rnk = 1
[BAD]
SELECT checksum(rnk)
FROM (
SELECT row_number() OVER (PARTITION BY l_orderkey, l_partkey ORDER BY l_shipdate DESC) AS rnk
FROM lineitem
) t
WHERE rnk = 1</code></pre>
</li>
<li><p>使用Presto分析统计数据时，可考虑把多次查询合并为一次查询，用Presto提供的子查询完成。</p>
<pre><code class="sql">WITH subquery_1 AS (
SELECT a1, a2, a3 
FROM Table_1 
WHERE a3 between 20180101 and 20180131
),               /*子查询subquery_1,注意：多个子查询需要用逗号分隔*/
subquery_2 AS (
SELECT b1, b2, b3
FROM Table_2
WHERE b3 between 20180101 and 20180131
)                /*最后一个子查询后不要带逗号，不然会报错。*/        
SELECT 
subquery_1.a1, subquery_1.a2, 
subquery_2.b1, subquery_2.b2
FROM subquery_1
JOIN subquery_2
ON subquery_1.a3 = subquery_2.b3;</code></pre>
</li>
<li><p>字段名与关键字冲突：MySQL对于关键字冲突的字段名加反引号，Presto对与关键字冲突的字段名加双引号。</p>
</li>
<li><p>Hive分析任务如何迁移Presto<br>Presto使用ANSI标准的SQL语法，Hive使用类SQL语法HQL<br>官方案例：<a href="https://prestodb.io/docs/current/migration/from-hive.html" target="_blank" rel="noopener">Migrating From Hive</a>  </p>
</li>
</ol>
<pre><code class="sql">-- 1.Presto使用下标取数组元素 下标从1开始
select id,
       arr[1] as arr2,
       arr[3] as arr3 
from
(SELECT * FROM (
    VALUES
        (1, &#39;a&#39;, ARRAY[1, 2, 3]),
        (2, &#39;b&#39;, ARRAY[4, 5, 6]),
        (3, &#39;c&#39;, ARRAY[7, 8, 9])
) AS t (id, name, arr)) a;
-- 2.不支持隐式数据类型转换，需要手动转换
SELECT
  CAST(x AS varchar)
, CAST(x AS bigint)
, CAST(x AS double)
, CAST(x AS boolean)
FROM ...
SELECT CAST(5 AS DOUBLE) / 2;SELECT 5 / 2;
-- 3.WITH AS语法
WITH a AS 
(SELECT uploader,videos
FROM tb_user_info
LIMIT 10) 
select * from a;
-- 4.UNNEST关键字代替LATERAL VIEW explode()进行行转列
Hive写法:
SELECT student, score
FROM tests
LATERAL VIEW explode(scores) t AS score;
Presto写法:
SELECT student, score
FROM tests
CROSS JOIN UNNEST(scores) AS t (score);
-- 5.Hive视图不支持通过Presto查询，所以要在Presto创建同名视图（即在presto读取视图定义(StatementAnalyzer.java)的时候，解析原始的sql定义的语句，转换成presto的视图结构）
-- 6.cast as string不支持，因为Presto的是Varchar，需要在ASTBuilder.java中把string替换为了varchar类型
-- 7.select 1 = &#39;1&#39;;在Hive和Presto计算结果分别为true,cannot be applied to integer, varchar(1) 需要额外操作实现透明的隐式转换
-- 8.UDF支持、null值处理
-- 9.对于timestamp类型字段做where条件比较，hive可以直接比较，presto需要加timestamp关键字
/*Hive的写法*/
SELECT t FROM a WHERE t &gt; &#39;2021-01-01 00:00:00&#39;; 
/*Presto中的写法*/
SELECT t FROM a WHERE t &gt; timestamp &#39;2021-01-01 00:00:00&#39;;
-- 10.Presto的MD5传入binary类型则会返回binary类型，所以对字符串的MD5需要转换：
SELECT to_hex(md5(to_utf8(&#39;abcd&#39;)));
-- 11.Presto不支持INSERT OVERWRITE，只能先DELETE再INSERT</code></pre>
<ol start="20">
<li>Hive数仓的数据安全性和权限<br>参考<a href="https://prestodb.io/docs/current/security/built-in-system-access-control.html" target="_blank" rel="noopener">Built-in System Access Control</a><br>在我看来hive.security=file形式的授权比较灵活<br>先配置全局的Catalog访问权限：<br>user:可选参数，正则匹配用户名，默认.*<br>catalog:可选参数，正则匹配Catalog名，默认.*.<br>allow:必选参数，用户是否对calalog有访问权限true\false</li>
</ol>
<pre><code class="shell"># 启用基于文件的权限控制
vim /opt/modules/presto-server-0.248/etc/access-control.properties
access-control.name=file
security.config-file=/opt/modules/presto-server-0.248/etc/rules.json
security.refresh-period=10s   # 配置权限自动刷新时间间隔 10s
# 设置权限控制规则：允许只admin用户有mysql catalog的权限，所有用户有hive catalog权限，所有用户无system catalog权限
vim /opt/modules/presto-server-0.248/etc/rules.json
{
  &quot;catalogs&quot;: [
    {
      &quot;user&quot;: &quot;admin&quot;,
      &quot;catalog&quot;: &quot;(mysql|system)&quot;,
      &quot;allow&quot;: true
    },
    {
      &quot;catalog&quot;: &quot;hive&quot;,
      &quot;allow&quot;: true
    },
    {
      &quot;catalog&quot;: &quot;system&quot;,
      &quot;allow&quot;: false
    }
  ]
}
分发access-control.properties和rules.json，重启PrestoServer生效
连接PrestoClient并指定用户presto --server cdh101:8080 --catalog hive --schema default --user qjj</code></pre>
<p>配置hive数据源的权限，参考<a href="https://prestodb.io/docs/current/connector/hive-security.html#" target="_blank" rel="noopener">Hive Security Configuration</a><br>有legacy,read-only,file,sql-standard四种形式，仍然是file的授权形式比较灵活</p>
<pre><code class="shell">vim etc/catalog/hive.properties
hive.security=file
security.config-file=/opt/modules/presto-server-0.248/etc/catalog/hive-security.json

vim /opt/modules/presto-server-0.248/etc/catalog/hive-security.json
{
  &quot;schemas&quot;: [
    {
      &quot;user&quot;: &quot;admin&quot;,
      &quot;schema&quot;: &quot;.*&quot;,
      &quot;owner&quot;: true
    },
    {
      &quot;user&quot;: &quot;staging&quot;,
      &quot;owner&quot;: false
    },
    {
      &quot;user&quot;: &quot;test&quot;,
      &quot;schema&quot;: &quot;test&quot;,
      &quot;owner&quot;: false
    }
  ],
  &quot;tables&quot;: [
    {
      &quot;user&quot;: &quot;admin&quot;,
      &quot;privileges&quot;: [&quot;SELECT&quot;, &quot;OWNERSHIP&quot;]
    },
    {
      &quot;user&quot;: &quot;staging&quot;,
      &quot;table&quot;: &quot;(staging_db_users|staging_db_videos).*&quot;,
      &quot;privileges&quot;: [&quot;SELECT&quot;]
    },
    {
      &quot;user&quot;: &quot;test&quot;,
      &quot;table&quot;: &quot;test.*&quot;,
      &quot;privileges&quot;: [&quot;SELECT&quot;]
    }
  ]
}
分发catalog/hive.properties、catalog/hive-security.json
重启Presto-server</code></pre>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>Hive\Spark的SQL任务迁移到Presto在语法、计算结果、视图使用、类型转换、UDF及空值处理上有差异</li>
<li>Hive\Spark任务迁移Presto，如果要做到对业务透明，还有很长的路要走</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://prestodb.io/docs" target="_blank" rel="noopener">Presto Documentation</a><br><a href="https://iceberg.apache.org/docs/latest/hive/" target="_blank" rel="noopener">Iceberg Hive Doc</a><br><a href="https://zhuanlan.zhihu.com/p/101366898" target="_blank" rel="noopener">深入理解Presto</a><br><a href="https://tech.meituan.com/2014/06/16/presto.html" target="_blank" rel="noopener">Presto实现原理和美团的使用实践</a><br><a href="https://blog.csdn.net/weixin_35698805/article/details/112362954" target="_blank" rel="noopener">Hive迁移Presto在OPPO的实践</a><br><a href="https://mp.weixin.qq.com/s/1N7Kd9E2dLB1OPhY_MTs6A" target="_blank" rel="noopener">零基础熟悉 Presto的概念、安装、使用及优化</a></p>

</div>


    <div class="post-guide">
        <div class="item left">
            
              <a href="/3f34ebe3/">
                  <i class="fa fa-angle-left" aria-hidden="true"></i>
                  
              </a>
            
        </div>
        <div class="item right">
            
              <a href="/BigdataExceptionsSummary/">
                
                <i class="fa fa-angle-right" aria-hidden="true"></i>
              </a>
            
        </div>
    </div>



	<div id="vcomments"></div>


<script>
	
		// 评论
		new Valine({
			av: AV,
			el: '#vcomments',
			notify: false,
			verify: false,
			path: window.location.pathname,
			appId: 'zUyVEaHo59RUUwiPTChPEeBj-gzGzoHsz',
			appKey: 'xIEyTcrkTuJLz6ewPbpTj8mz',
			placeholder: '欢迎评论...',
			avatar: 'retro',
			recordIP: false
		})
	
	
</script>
	</div>
	<div id="footer">
	<p>
	©2020-<span id="footerYear"></span> 
	<a href="/">佳境Shmily</a> 
	
	
		|
		<span id="busuanzi_container_site_pv">
			pv
			<span id="busuanzi_value_site_pv"></span>
		</span>
		|
		<span id="busuanzi_container_site_uv"> 
			uv
			<span id="busuanzi_value_site_uv"></span>
		</span>
	
	<br>
	Theme <a href="//github.com/wujun234/hexo-theme-tree" target="_blank">Tree</a>
	by <a href="//github.com/wujun234" target="_blank">WuJun</a>
	Powered by <a href="//hexo.io" target="_blank">Hexo</a>
	</p>
</div>
<script type="text/javascript"> 
	document.getElementById('footerYear').innerHTML = new Date().getFullYear() + '';
</script>
	<button id="totop-toggle" class="toggle"><i class="fa fa-angle-double-up" aria-hidden="true"></i></button>
</body>
</html>